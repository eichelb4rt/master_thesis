\chapter{Nested Expressions}

In practice, concatenations of operations come naturally, e.g. computing the squared norm of a matrix-vector product $\abs{A \cdot v}_2^2$
for $A \in \R^{m \times n}, v \in \R^n$.
This would lead to a nested Einsum expression $\abs{A \cdot v}_2^2 = (i,i \rightarrow , (ij, j \rightarrow i, A, v), (ij, j \rightarrow i, A, v))$.
This expression dictates the order of evaluating the expression.
In the example of the norm, the expression $(ij, j \rightarrow i, A, v)$ has to be evaluated before squaring and summing over the results of this computation.

This is limiting, because the order of evaluation might not yield optimal runtime.
This can be seen with a simple matrix-matrix-vector multiplication, which can be written as follows:
$$(A \cdot B) \cdot v = (ij, j \rightarrow i, (ik, kj \rightarrow ij, A, B), v)$$
which is clearly worse than the optimal contraction order
$$A \cdot (B \cdot v) = (ij, j \rightarrow i, A, (ij, j \rightarrow i, B, v))$$
for $A \in \R^{m \times r}, B \in \R^{r \times n}, v \in \R^n$.

But fortunately, all nested Einsum expressions can be compressed into a single Einsum expression, if they are computed over the same semiring.
This leaves the path of contraction up to the implementation.
In the following theorems, we assume that the computations are all over the same semiring $R = (M, \oplus, \odot)$.

\input{chapters/nested/thm_1.tex}

This means that we can compress all nested Einsum expressions, where the output string of the inner expression, which is used to compute $U$, is exactly the same as the respective input string in the outer expression, when $U$ is used as an input tensor.
This is already helpful for naturally occuring expressions in linear algebra, e.g.
\begin{align*}
    \abs{A \cdot v}_2^2 & = (i,i\rightarrow,(ij, j \rightarrow i, A, v),(ij, j \rightarrow i, A, v)) \\
                        & = (ij,j,ij,j\rightarrow,A,v,A,v)
\end{align*}
for $A \in \R^{m \times n}, v \in \R^{n}$, or
\begin{align*}
    A \cdot B \cdot v & = (ij, j \rightarrow i, (ik, kj \rightarrow ij, A, B), v) \\
                      & = (ik,kj,j \rightarrow i, A, B, v)
\end{align*}
for $A \in \R^{m \times r}, B \in \R^{r \times n}, v \in \R^n$.
But sometimes, we need to access a different multi-index set than the one we computed, e.g.
$$\text{trace}(A \cdot B) = (ii \rightarrow, (ik, kj \rightarrow ij, A, B))$$
or
$$A \cdot \text{diag}(v) = (ik, kj \rightarrow ij, A, (i \rightarrow ii, v))$$
for $A \in \R^{m \times n}, B \in \R^{n \times m}, v \in \R^{n}$.
For this, we need more general ways of compressing nested Einsum expressions.

\input{chapters/nested/thm_2.tex}

With this theorem, we can prove a property of the trace in a relatively simple manner, namely that for $A \in \R^{m \times n}, B \in \R^{n \times m}$,
it holds that
$$\text{trace}(A \cdot B) = \text{trace}(B \cdot A).$$

\begin{proof}
    \small
    % \begin{align*}
    %     \text{trace}(A \cdot B) & = (ii \rightarrow , (ik,kj \rightarrow ij, A, B)) \\
    %                             & = (ik, ki \rightarrow ,A, B)                      \\
    %                             & = (ki, ik \rightarrow ,A, B)                      \\
    %                             & = (ik, ki \rightarrow ,B, A)                      \\
    %                             & = (ii \rightarrow , (ik,kj \rightarrow ij, B, A)) \\
    %                             & = \text{trace}(B \cdot A)
    % \end{align*}
    % where the second equality holds because of \autoref{thm:nested_einsum:2},
    % the third equality is just a renaming of the indices,
    % and the fourth equality holds because of the commutivity in the used semiring.
    \begin{align*}
        \text{trace}(A \cdot B) & = (ii \rightarrow , (ik,kj \rightarrow ij, A, B)) \\
                                & = (ik, ki \rightarrow ,A, B)                      \\
                                & = (ki, ik \rightarrow ,B, A)                      \\
                                & = \text{trace}(B \cdot A)
    \end{align*}
    where the second equality holds because of \autoref{thm:nested_einsum:2},
    and the third equality holds because of the commutativity of multiplication in the standard semiring.
\end{proof}
\bigskip

This is already a useful tool for compressing nested expressions, but there are still some naturally occuring expressions we cannot compress with this,
e.g.:
$$A \cdot \text{diag}(v) = (ik, kj \rightarrow ij, A, (i \rightarrow ii, v))$$
for $A \in \R^{m \times n}, v \in \R^{n}$.
This is because the symbol duplication $ii$ is broken by the index string $kj$, and therefore we access more entries than the ones we computed.

\input{chapters/nested/thm_3.tex}

With these theorems, we can write some more complex expressions from linear algebra as a single Einsum expression respectively:
\begin{itemize}
    \item squared norm of matrix-vector multiplication: Let $A \in \R^{m \times n}, v \in \R^{n}$. Then
          \begin{align*}
              \abs{A \cdot v}_2^2 & = (i,i\rightarrow,(ij, j \rightarrow i, A, v),(ij, j \rightarrow i, A, v)) \\
                                  & = (ij,j,ij,j\rightarrow,A,v,A,v)
          \end{align*}
    \item trace of matrix-matrix multiplication: Let $A \in \R^{m \times n}, B \in \R^{n \times m}$. Then
          \begin{align*}
              \text{trace}(A \cdot B) & = (ii \rightarrow, (ik, kj \rightarrow ij, A, B)) \\
                                      & = (ik, ki \rightarrow, A, B)
          \end{align*}
    \item matrix multiplication with a diagonal matrix: Let $A \in \R^{m \times n}, v \in \R^{n}$. Then
          \begin{align*}
              A \cdot \text{diag}(v) & = (ik, kj \rightarrow ij, A, (i \rightarrow ii, v)) \\
                                     & = (ij, j \rightarrow ij, A, v)                      \\
          \end{align*}
\end{itemize}

\input{chapters/nested/thm_4.tex}
